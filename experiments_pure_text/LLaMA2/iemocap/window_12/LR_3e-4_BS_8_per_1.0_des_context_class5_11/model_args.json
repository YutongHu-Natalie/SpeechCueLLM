{
     "model_type": "decoder",
     "model_name_or_path": "/local/scratch/yhu383/models/llama2-7b",
     "checkpoint_dir": null,
     "output_dir": "../new_experiments/LLaMA2/lora/iemocap/window_12/LR_3e-4_BS_8_per_1.0_des_context_class5_11",
     "data_dir": "../PROCESSED_DATASET/iemocap/window/False_False",
     "do_train": true,
     "do_eval": true,
     "warmup_ratio": 0.1,
     "warmup_steps": 969,
     "save_steps": 100000,
     "weight_decay": 0.0,
     "max_seq_length": 256,
     "max_length": 2500,
     "num_beams": 1,
     "do_sample": false,
     "top_k": null,
     "top_p": null,
     "learning_rate": 0.0003,
     "preprocess_inputs": true,
     "clip_norm": 1.0,
     "open_ended": false,
     "batch_size": 8,
     "eval_batch_size": 8,
     "gradient_accumulation_steps": 8,
     "lora": true,
     "lora_dim": 16,
     "lora_alpha": 16,
     "lora_dropout": 0.05,
     "lora_module_name": "q_proj,k_proj,v_proj,query_key_value",
     "seed": 11,
     "offload_optimizer": false,
     "deepspeed_config": "/local/scratch/yhu383/SpeechCueLLM/LLM_code/data_utils/deepspeed_config_7b_8b.json",
     "zero_shot": true,
     "mode": "sft",
     "gradient_checkpointing": false,
     "use_chat_template": "auto"
}