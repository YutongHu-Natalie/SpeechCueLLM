Job started at Mon Nov 10 09:35:56 AM EST 2025
Running on host: h100server
Job ID: 62186
******************************************************************************************
All parameters are valid.
The dataset you have selected is: iemocap !
The base model you have selected is LLaMA3-instruct!
The model's SFT method you have selected: few_shot!
If predict emotions: False
******************************************************************************************
******************************************************************************************
Data procession has executed successfully !
******************************************************************************************
******************************************************************************************
Your choose iemocap! The max_context_length will be set as 2500!
******************************************************************************************
Your choose LLaMA3-instruct! Model Parameters should be initialized in the path 
 /local/scratch/yhu383/models/llama3.1-8b
Your choose few_shot! The experiment will be set as FEW_SHOT model
Processed Data_Path: ../PROCESSED_DATASET/iemocap/window/True_False
[2025-11-10 09:36:14,057] [WARNING] [runner.py:191:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0: setting --include=localhost:0
[2025-11-10 09:36:14,092] [INFO] [runner.py:541:main] cmd = /local/scratch/yhu383/SpeechCueLLM/venv/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=26000 --enable_each_rank_log=None main.py --dataset iemocap --model_name_or_path /local/scratch/yhu383/models/llama3.1-8b --data_dir ../PROCESSED_DATASET/iemocap/window/True_False --output_dir ../experiments/LLaMA3-instruct/few_shot/iemocap/window_12/LR_0_BS_8_per_1.0_des_context_class5_42 --max_length 2500 --batch_size 8 --deepspeed_config ../LLM_code/data_utils/deepspeed_config.json --gradient_accumulation_steps 8 --eval_batch_size 8 --num_train_epochs 15 --save_steps 100000 --lora False --learning_rate 0 --do_eval True --do_train False --statistic_mode True --data_percent 1.0 --seed 42 --emotion_prediction False
[2025-11-10 09:36:16,901] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [0]}
[2025-11-10 09:36:16,901] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2025-11-10 09:36:16,901] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2025-11-10 09:36:16,901] [INFO] [launch.py:247:main] dist_world_size=1
[2025-11-10 09:36:16,901] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=0
ModelArgs(model_type='decoder', model_name_or_path='/local/scratch/yhu383/models/llama3.1-8b', checkpoint_dir=None, output_dir='../experiments/LLaMA3-instruct/few_shot/iemocap/window_12/LR_0_BS_8_per_1.0_des_context_class5_42', data_dir='../PROCESSED_DATASET/iemocap/window/True_False', do_train=False, do_eval=True, warmup_ratio=0.1, warmup_steps=None, save_steps=100000, weight_decay=0.0, max_seq_length=256, max_length=2500, num_beams=1, do_sample=False, top_k=None, top_p=None, learning_rate=0.0, preprocess_inputs=True, clip_norm=1.0, open_ended=False, batch_size=8, eval_batch_size=8, gradient_accumulation_steps=8, lora=False, lora_dim=16, lora_alpha=16, lora_dropout=0.05, lora_module_name='q_proj,k_proj,v_proj,query_key_value', seed=42, offload_optimizer=False, deepspeed_config='../LLM_code/data_utils/deepspeed_config.json', zero_shot=True, mode='sft', gradient_checkpointing=False)
the number of num_samples is 1623
the number of num_samples is 1623
[2025-11-10 09:37:45,135] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.2, git-hash=unknown, git-branch=unknown
[2025-11-10 09:37:45,136] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead
[2025-11-10 09:37:45,136] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1

*****    Evaluating  *****

{'Acc_SA': 9.55, 'F1_SA': 2.718, 'mode': 'test'}
[2025-11-10 09:38:56,067] [INFO] [launch.py:460:main] Process 330673 exits successfully.
Job finished at Mon Nov 10 09:39:04 AM EST 2025
